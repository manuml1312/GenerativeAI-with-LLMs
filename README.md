# GenerativeAI-with-LLMs

This repository contains the code for inferencing and finetuning a LLM as per the application requirements.

# 1.Zero,One_and_Few_shot_inference.ipynb:
This contains the necessary code for inferencing a Seq2Seq transformer to generate summaries for a dialogue-summary dataset.Includes prompt engineering for inferencing with the help of Zero shot,One shot and Few shots method.
# 2.LLM_finetuning_with_PEFT.ipynb: 
Contains the code for fully finetuning and partial finetuning of the LLM through PEFT that helps to reduce the memory footprint and the time associated with involved in finetuning a LLM model.The results are further evaluated with Human evaluation and ROUGE Metric evaluation.Partial finetuning of the LLM with PEFT is a significant method to improve the output of the LLM whose results are very close to those obtained through the complete finetuning of the LLM model.
